{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9966d0cb-b142-4d43-9fe4-b36510fb09b2",
   "metadata": {},
   "source": [
    "# iSyncTab Demo Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d71376-e219-4694-a461-8a700b9ee6fe",
   "metadata": {},
   "source": [
    "### Demo configuration (read this before running)\n",
    "\n",
    "> **Attention:**  \n",
    "> This script is configured as a **demo run** of **iSyncTab + NS-PFS** on the **HAM10000** dataset, using:\n",
    "> - **Optuna** with `N_TRIALS = 5`\n",
    "> - **Final training** with `FINAL_EPOCHS = 5`\n",
    "> - **Tuning** with `EPOCHS_TUNE = 3`\n",
    "\n",
    "For a **full experiment**, you should **increase**:\n",
    "- `N_TRIALS` &nbsp;→ more Optuna trials  \n",
    "- `FINAL_EPOCHS` → more epochs for the final train on train+val  \n",
    "- Optionally `EPOCHS_TUNE` → more epochs per trial during tuning\n",
    "\n",
    "The code will:\n",
    "- Run Optuna hyperparameter search on the validation set  \n",
    "- Print the **best validation objective** and the corresponding **best hyperparameters**  \n",
    "- Retrain iSyncTab on the **combined train+val split** using those best hyperparameters  \n",
    "- Report the final **test accuracy** and **test loss** on HAM10000\n",
    "\n",
    "---\n",
    "\n",
    "### Required Python packages\n",
    "\n",
    "Make sure these libraries are installed in your environment:\n",
    "\n",
    "```bash\n",
    "pip install torch torchvision linformer optuna pandas numpy pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6597622e-5ce7-4b58-bb67-ffb4ef039ad5",
   "metadata": {},
   "source": [
    "### HAM10000 dataset preparation\n",
    "\n",
    "We use the **HAM10000** dataset from Kaggle and assume a simple layout:\n",
    "\n",
    "- One folder containing **all images**: `ham_images_link/`\n",
    "- One processed metadata file: `HAM10000_metadata_processed.csv`\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Download HAM10000 from Kaggle\n",
    "\n",
    "Source (Kaggle):  \n",
    "https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000\n",
    "\n",
    "Download and extract the archive locally. You should get:\n",
    "- Image folders such as `HAM10000_images_part_1`, `HAM10000_images_part_2`, …\n",
    "- A metadata CSV like `HAM10000_metadata.csv`\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Put all images into a single folder\n",
    "\n",
    "Create a directory in your working path, for example:\n",
    "\n",
    "```text\n",
    "ham_images_link/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0f9142-3f1c-45e6-a9f5-65294671df9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aca689b-d81c-4691-a51b-ed0d65f3d9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-21 00:59:39,615] A new study created in memory with name: no-name-3ea1bec3-35fb-492b-a160-10e035324833\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c830be27754689a96501f63045fe6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 00] val_acc=0.8103, lambda_fs=0.217, objective=0.8103\n",
      "[I 2025-11-21 01:26:00,601] Trial 0 finished with value: 0.8103233830845771 and parameters: {'d_model': 128, 'linformer_heads': 4, 'linformer_depth': 5, 'linformer_k': 16, 'num_memory_tokens': 2, 'num_clusters': 6, 'metric': 'correlation', 'lr': 0.0002090220546562389, 'weight_decay': 2.882541940368984e-05, 'batch_size': 8, 'lambda_fs': 0.21673301477106646}. Best is trial 0 with value: 0.8103233830845771.\n",
      "[Trial 01] val_acc=0.8057, lambda_fs=0.184, objective=0.8057\n",
      "[I 2025-11-21 01:40:23,233] Trial 1 finished with value: 0.8056930693069307 and parameters: {'d_model': 192, 'linformer_heads': 4, 'linformer_depth': 4, 'linformer_k': 32, 'num_memory_tokens': 1, 'num_clusters': 5, 'metric': 'euclidean', 'lr': 0.0003323304105591294, 'weight_decay': 3.769687142814138e-06, 'batch_size': 16, 'lambda_fs': 0.1838683577288903}. Best is trial 0 with value: 0.8103233830845771.\n",
      "[Trial 02] val_acc=0.7730, lambda_fs=0.005, objective=0.7730\n",
      "[I 2025-11-21 02:01:37,946] Trial 2 finished with value: 0.7730099502487562 and parameters: {'d_model': 192, 'linformer_heads': 2, 'linformer_depth': 4, 'linformer_k': 32, 'num_memory_tokens': 3, 'num_clusters': 5, 'metric': 'cosine', 'lr': 0.00022113293535948466, 'weight_decay': 1.6604942333073266e-06, 'batch_size': 8, 'lambda_fs': 0.004838762008505048}. Best is trial 0 with value: 0.8103233830845771.\n",
      "[Trial 03] val_acc=0.8007, lambda_fs=0.103, objective=0.8007\n",
      "[I 2025-11-21 02:11:20,799] Trial 3 finished with value: 0.8007425742574258 and parameters: {'d_model': 128, 'linformer_heads': 4, 'linformer_depth': 5, 'linformer_k': 64, 'num_memory_tokens': 3, 'num_clusters': 4, 'metric': 'kl', 'lr': 0.00022757685387296938, 'weight_decay': 3.9050498915357826e-05, 'batch_size': 16, 'lambda_fs': 0.10303680421449747}. Best is trial 0 with value: 0.8103233830845771.\n",
      "[Trial 04] val_acc=0.8186, lambda_fs=0.271, objective=0.8186\n",
      "[I 2025-11-21 02:20:34,731] Trial 4 finished with value: 0.8186274509803921 and parameters: {'d_model': 192, 'linformer_heads': 8, 'linformer_depth': 5, 'linformer_k': 32, 'num_memory_tokens': 1, 'num_clusters': 4, 'metric': 'euclidean', 'lr': 0.00039358925581145943, 'weight_decay': 0.00012112063022493961, 'batch_size': 32, 'lambda_fs': 0.27057341179820116}. Best is trial 4 with value: 0.8186274509803921.\n",
      "\n",
      "=== Best (validation objective) ===\n",
      "Score = 0.8186\n",
      "d_model: 192\n",
      "linformer_heads: 8\n",
      "linformer_depth: 5\n",
      "linformer_k: 32\n",
      "num_memory_tokens: 1\n",
      "num_clusters: 4\n",
      "metric: euclidean\n",
      "lr: 0.00039358925581145943\n",
      "weight_decay: 0.00012112063022493961\n",
      "batch_size: 32\n",
      "lambda_fs: 0.27057341179820116\n",
      "[Final Train] Epoch 01 | loss=0.6135 | acc=0.7778\n",
      "[Final Train] Epoch 02 | loss=0.3541 | acc=0.8652\n",
      "[Final Train] Epoch 03 | loss=0.2732 | acc=0.9003\n",
      "[Final Train] Epoch 04 | loss=0.1738 | acc=0.9367\n",
      "[Final Train] Epoch 05 | loss=0.1399 | acc=0.9507\n",
      "\n",
      "=== FINAL TEST RESULTS (iSyncTab + NS-PFS, HAM10000) ===\n",
      "Test accuracy: 0.8325\n",
      "Test loss:     0.9176\n",
      "Classes: ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n"
     ]
    }
   ],
   "source": [
    "# ============================ QUIET LOGS ============================\n",
    "import os, warnings\n",
    "warnings.filterwarnings(\"ignore\", message=r\"Deterministic behavior.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=r\".*does not have a deterministic implementation.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch\")\n",
    "os.environ.pop(\"CUBLAS_WORKSPACE_CONFIG\", None)\n",
    "\n",
    "# ============================ IMPORTS ===============================\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as T\n",
    "from torch import optim\n",
    "import optuna\n",
    "\n",
    "# Your model (simple iSyncTab)\n",
    "from iSyncTab import iSyncTab, set_seed\n",
    "\n",
    "# ============================ USER PATHS ============================\n",
    "# Processed HAM metadata with columns:\n",
    "# lesion_id, image_id, dx, dx_type, age, sex, localization, filename\n",
    "CSV_PATH = \"HAM10000_metadata_processed.csv\"\n",
    "IMG_ROOT = \"ham_images_link\"  # directory containing image files\n",
    "\n",
    "# ============================ DEVICE PICKER (fixed to cuda:6) =======\n",
    "def pick_device(force_idx=6):\n",
    "    if torch.cuda.is_available():\n",
    "        if force_idx < torch.cuda.device_count():\n",
    "            torch.cuda.set_device(force_idx)\n",
    "            return torch.device(f\"cuda:{force_idx}\")\n",
    "        torch.cuda.set_device(0)\n",
    "        return torch.device(\"cuda:0\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "set_seed(123)\n",
    "device = pick_device()\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ============================ HELPERS ===============================\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\", \".tif\", \".tiff\"}\n",
    "\n",
    "def _has_img_ext(x: str) -> bool:\n",
    "    s = str(x).lower().strip()\n",
    "    return any(s.endswith(ext) for ext in IMG_EXTS)\n",
    "\n",
    "def _ensure_jpg(x: str) -> str:\n",
    "    s = str(x).strip()\n",
    "    return s if _has_img_ext(s) else (s + \".jpg\")\n",
    "\n",
    "# ============================ DATASET ===============================\n",
    "class HamDataset(Dataset):\n",
    "    \"\"\"\n",
    "    HAM10000 multimodal dataset (processed version):\n",
    "      Required columns:\n",
    "        lesion_id, image_id, dx, dx_type, age, sex, localization, filename\n",
    "      - Image: IMG_ROOT / filename  (fallback: image_id + '.jpg' if needed)\n",
    "      - Tabular features:\n",
    "          * Numeric: age\n",
    "          * Categorical: dx_type, sex, localization\n",
    "      - Target: dx (string → label-encoded integer)\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_path, img_root, transform=None):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.img_root = Path(img_root)\n",
    "        self.transform = transform\n",
    "\n",
    "        required_cols = {\n",
    "            \"lesion_id\", \"image_id\", \"dx\", \"dx_type\",\n",
    "            \"age\", \"sex\", \"localization\", \"filename\"\n",
    "        }\n",
    "        missing = required_cols - set(df.columns)\n",
    "        if missing:\n",
    "            raise AssertionError(f\"CSV missing required columns: {missing}\")\n",
    "\n",
    "        # ----- target & class names from dx -----\n",
    "        dx_str = df[\"dx\"].astype(str)\n",
    "        classes = sorted(dx_str.unique().tolist())\n",
    "        mapping = {c: i for i, c in enumerate(classes)}\n",
    "        df[\"label\"] = dx_str.map(mapping).astype(int)\n",
    "\n",
    "        self.classes = classes\n",
    "        self.class_to_id = mapping\n",
    "        self.id_to_class = {i: c for c, i in mapping.items()}\n",
    "        self.y = torch.tensor(df[\"label\"].to_numpy(), dtype=torch.long)\n",
    "        self.n_classes = len(self.classes)\n",
    "\n",
    "        # ----- resolve image paths -----\n",
    "        keep_idx, img_paths = [], []\n",
    "        for i, row in df.iterrows():\n",
    "            # Prefer filename column\n",
    "            fname = str(row[\"filename\"])\n",
    "            p = self.img_root / fname\n",
    "            if not p.exists():\n",
    "                # Fallback to image_id + .jpg if needed\n",
    "                iid = str(row[\"image_id\"])\n",
    "                name = iid if _has_img_ext(iid) else _ensure_jpg(iid)\n",
    "                p = self.img_root / name\n",
    "            if p.exists():\n",
    "                keep_idx.append(i)\n",
    "                img_paths.append(p)\n",
    "\n",
    "        if not keep_idx:\n",
    "            raise RuntimeError(\"No valid images found under IMG_ROOT using 'filename' or 'image_id'.\")\n",
    "\n",
    "        df = df.iloc[keep_idx].reset_index(drop=True)\n",
    "        self.img_paths = img_paths\n",
    "        self.y = self.y[keep_idx]\n",
    "\n",
    "        # ----- build feature lists explicitly -----\n",
    "        # We use only: age (numeric), dx_type/sex/localization (categorical)\n",
    "        self.num_cols = [\"age\"]\n",
    "        self.cat_cols = [\"dx_type\", \"sex\", \"localization\"]\n",
    "        self.text_cols = []  # none\n",
    "\n",
    "        # numeric tensor (age)\n",
    "        num_df = df[self.num_cols].astype(float)\n",
    "        # keep NaNs; TabularTokenEncoder does median imputation\n",
    "        self.x_num = torch.tensor(num_df.to_numpy(copy=True), dtype=torch.float32)\n",
    "\n",
    "        # categorical -> ids (per-column vocab, -1 for missing/unseen)\n",
    "        self.x_cat = None\n",
    "        self._cat_vocabs = {}\n",
    "        cat_arrays = []\n",
    "        for col in self.cat_cols:\n",
    "            vals = df[col].astype(\"object\")\n",
    "            uniq_vals = sorted({str(v) for v in vals.dropna().unique().tolist()})\n",
    "            vocab = {tok: i for i, tok in enumerate(uniq_vals)}\n",
    "            self._cat_vocabs[col] = vocab\n",
    "            ids = [vocab.get(str(v), -1) if pd.notna(v) else -1 for v in vals]\n",
    "            cat_arrays.append(torch.tensor(ids, dtype=torch.long))\n",
    "        if cat_arrays:\n",
    "            self.x_cat = torch.stack(cat_arrays, dim=1)\n",
    "        else:\n",
    "            self.x_cat = torch.zeros((len(df), 0), dtype=torch.long)\n",
    "\n",
    "        # dummy text channel so EmbeddingBag never sees O_text=0\n",
    "        self.x_text = torch.zeros((len(df), 1, 1), dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        img = Image.open(img_path)\n",
    "        if img.mode != \"RGB\":\n",
    "            img = img.convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        x_num  = self.x_num[idx] if self.x_num.numel() else torch.zeros(0, dtype=torch.float32)\n",
    "        x_cat  = self.x_cat[idx] if self.x_cat is not None else torch.zeros(0, dtype=torch.long)\n",
    "        x_text = self.x_text[idx]  # (1,1)\n",
    "        y      = self.y[idx]\n",
    "\n",
    "        # shape to (1, O_*) to match TabularTokenEncoder expectations\n",
    "        x_tab = {\n",
    "            \"num\":  x_num.unsqueeze(0),\n",
    "            \"cat\":  x_cat.unsqueeze(0),\n",
    "            \"text\": x_text.unsqueeze(0)\n",
    "        }\n",
    "        return x_tab, img, y\n",
    "\n",
    "# -------------- Collate --------------\n",
    "def collate(batch):\n",
    "    x_tab_b, x_img_b, y_b = zip(*batch)\n",
    "    x_num_b  = torch.cat([b[\"num\"]  for b in x_tab_b], dim=0)\n",
    "    if x_tab_b[0][\"cat\"].numel():\n",
    "        x_cat_b = torch.cat([b[\"cat\"] for b in x_tab_b], dim=0)\n",
    "    else:\n",
    "        x_cat_b = torch.zeros((len(x_tab_b), 0), dtype=torch.long)\n",
    "    x_text_b = torch.cat([b[\"text\"] for b in x_tab_b], dim=0)\n",
    "    x_tab_batch = {\"num\": x_num_b, \"cat\": x_cat_b, \"text\": x_text_b}\n",
    "    x_img_b = torch.stack(x_img_b)\n",
    "    y_b     = torch.tensor(y_b)\n",
    "    return x_tab_batch, x_img_b, y_b\n",
    "\n",
    "def accuracy_from_logits(logits, y):\n",
    "    return (logits.argmax(dim=1) == y).float().mean().item()\n",
    "\n",
    "# ========================== DATA & LOADERS ===========================\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])  # ImageNet\n",
    "])\n",
    "\n",
    "ds = HamDataset(CSV_PATH, IMG_ROOT, transform=transform)\n",
    "\n",
    "n_classes = ds.n_classes\n",
    "N = len(ds)\n",
    "n_train = int(round(0.64 * N))\n",
    "n_val   = int(round(0.16 * N))\n",
    "n_test  = N - n_train - n_val\n",
    "assert n_train > 0 and n_val > 0 and n_test > 0, f\"Bad split sizes (N={N}).\"\n",
    "\n",
    "g = torch.Generator().manual_seed(123)\n",
    "ds_train, ds_val, ds_test = random_split(ds, [n_train, n_val, n_test], generator=g)\n",
    "\n",
    "def make_loaders(batch_size):\n",
    "    pin = device.type == \"cuda\"\n",
    "    dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True,\n",
    "                          num_workers=0, pin_memory=pin, collate_fn=collate)\n",
    "    dl_val   = DataLoader(ds_val,   batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=0, pin_memory=pin, collate_fn=collate)\n",
    "    dl_test  = DataLoader(ds_test,  batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=0, pin_memory=pin, collate_fn=collate)\n",
    "    return dl_train, dl_val, dl_test\n",
    "\n",
    "# token hint = numeric + categorical + (dummy) text(=1)\n",
    "NUM_TAB_FEATURES = len(ds.num_cols) + len(ds.cat_cols) + 1\n",
    "\n",
    "# ====================== SAFETY HOOK (nspfs -> Long valid indices) ======================\n",
    "def _install_nspfs_safety_hook(model: torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Ensure model.nspfs forward returns Long indices in [0, L-1].\n",
    "    \"\"\"\n",
    "    if not hasattr(model, \"nspfs\") or not isinstance(model.nspfs, torch.nn.Module):\n",
    "        return None\n",
    "\n",
    "    def hook(mod, inputs, output):\n",
    "        try:\n",
    "            t_tok = inputs[0]; i_tok = inputs[1]\n",
    "            L = int(t_tok.size(1) + i_tok.size(1))\n",
    "        except Exception:\n",
    "            L = None\n",
    "            t_tok = None\n",
    "        if isinstance(output, torch.Tensor):\n",
    "            if output.dtype != torch.long:\n",
    "                output = output.long()\n",
    "            if (L is not None) and output.numel() > 0:\n",
    "                output = output.clamp_(0, max(L - 1, 0))\n",
    "            if t_tok is not None and isinstance(t_tok, torch.Tensor):\n",
    "                output = output.to(t_tok.device)\n",
    "        return output\n",
    "\n",
    "    handle = model.nspfs.register_forward_hook(hook)\n",
    "    return handle\n",
    "\n",
    "# ============================ MODEL ================================\n",
    "def build_model(params):\n",
    "    core = dict(\n",
    "        num_tab_features = NUM_TAB_FEATURES,\n",
    "        num_classes      = n_classes,\n",
    "        num_clusters     = params[\"num_clusters\"],\n",
    "        metric           = params[\"metric\"],\n",
    "        lambda_fs        = params[\"lambda_fs\"],\n",
    "        pretrained_resnet= True\n",
    "    )\n",
    "    opt_kwargs = dict(\n",
    "        d_model         = params.get(\"d_model\"),\n",
    "        linformer_depth = params.get(\"linformer_depth\"),\n",
    "        linformer_heads = params.get(\"linformer_heads\"),\n",
    "        linformer_k     = params.get(\"linformer_k\"),\n",
    "    )\n",
    "    opt_kwargs = {k: v for k, v in opt_kwargs.items() if v is not None}\n",
    "    try:\n",
    "        model = iSyncTab(**core, **opt_kwargs).to(device)\n",
    "    except TypeError:\n",
    "        model = iSyncTab(**core).to(device)\n",
    "\n",
    "    # install safety hook (kept as attribute to avoid GC)\n",
    "    model._nspfs_hook_handle = _install_nspfs_safety_hook(model)\n",
    "    return model\n",
    "\n",
    "def run_epoch(model, loader, opt=None):\n",
    "    train = opt is not None\n",
    "    model.train(train)\n",
    "    losses, accs = [], []\n",
    "    for x_tab, img, y in loader:\n",
    "        img, y = img.to(device), y.to(device)\n",
    "        x_tab = {k: v.to(device) for k, v in x_tab.items()}\n",
    "        out = model(x_tab, img, y=y)\n",
    "        if train:\n",
    "            opt.zero_grad()\n",
    "            out[\"loss\"].backward()\n",
    "            opt.step()\n",
    "        losses.append(out[\"loss\"].item())\n",
    "        accs.append(accuracy_from_logits(out[\"logits\"], y))\n",
    "    return (float(np.mean(losses)) if losses else 0.0,\n",
    "            float(np.mean(accs))   if accs   else 0.0)\n",
    "\n",
    "# ================================ OPTUNA =============================\n",
    "# Objective = for best performance\n",
    "PENALIZE_LAMBDA = 0.0\n",
    "EPOCHS_TUNE     = 3\n",
    "FINAL_EPOCHS    = 5\n",
    "\n",
    "def suggest_params(trial):\n",
    "    return {\n",
    "        \"d_model\": trial.suggest_categorical(\"d_model\", [128, 192, 256]),\n",
    "        \"linformer_heads\": trial.suggest_categorical(\"linformer_heads\", [2, 4, 8]),\n",
    "        \"linformer_depth\": trial.suggest_int(\"linformer_depth\", 3, 5),\n",
    "        \"linformer_k\": trial.suggest_categorical(\"linformer_k\", [16, 32, 64]),\n",
    "        \"num_memory_tokens\": trial.suggest_int(\"num_memory_tokens\", 1, 3),\n",
    "        \"num_clusters\": trial.suggest_int(\"num_clusters\", 3, 7),\n",
    "        \"metric\": trial.suggest_categorical(\"metric\", [\"variance\", \"euclidean\", \"cosine\", \"correlation\", \"kl\", \"js\", \"manhattan\"]),\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-4, 4e-4, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 2e-4, log=True),\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [8, 16, 32]),\n",
    "        \"lambda_fs\": trial.suggest_float(\"lambda_fs\", 0.0, 0.3),\n",
    "    }\n",
    "\n",
    "def objective(trial):\n",
    "    params = suggest_params(trial)\n",
    "\n",
    "    # sanity: d_model divisible by heads\n",
    "    if params[\"d_model\"] % params[\"linformer_heads\"] != 0:\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    set_seed(1000 + trial.number)\n",
    "    dl_train, dl_val, _ = make_loaders(params[\"batch_size\"])\n",
    "\n",
    "    model = build_model(params)\n",
    "    opti  = optim.AdamW(model.parameters(), lr=params[\"lr\"], weight_decay=params[\"weight_decay\"])\n",
    "\n",
    "    # warmup (optional, to initialize NSPFS etc.)\n",
    "    try:\n",
    "        x_tab_b, img_b, y_b = next(iter(dl_train))\n",
    "        img_b, y_b = img_b.to(device), y_b.to(device)\n",
    "        x_tab_b = {k: v.to(device) for k, v in x_tab_b.items()}\n",
    "        _ = model(x_tab_b, img_b, y=y_b)\n",
    "    except StopIteration:\n",
    "        pass\n",
    "\n",
    "    for _ in range(EPOCHS_TUNE):\n",
    "        run_epoch(model, dl_train, opt=opti)\n",
    "\n",
    "    _, val_acc = run_epoch(model, dl_val, opt=None)\n",
    "    obj = float(val_acc - PENALIZE_LAMBDA * params[\"lambda_fs\"])\n",
    "\n",
    "    print(f\"[Trial {trial.number:02d}] val_acc={val_acc:.4f}, \"\n",
    "          f\"lambda_fs={params['lambda_fs']:.3f}, objective={obj:.4f}\")\n",
    "\n",
    "    return obj\n",
    "\n",
    "# Keep Optuna metadata minimal (no explicit study_name)\n",
    "N_TRIALS = 5\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=123)\n",
    ")\n",
    "study.optimize(objective, n_trials=N_TRIALS,\n",
    "               gc_after_trial=True, show_progress_bar=True)\n",
    "\n",
    "print(\"\\n=== Best (validation objective) ===\")\n",
    "print(f\"Score = {study.best_value:.4f}\")\n",
    "best = study.best_trial.params\n",
    "for k, v in best.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# ==================== RETRAIN BEST + TEST EVAL =======================\n",
    "set_seed(777)\n",
    "dl_train_best, dl_val_best, dl_test_best = make_loaders(best[\"batch_size\"])\n",
    "\n",
    "# Merge train+val for final training\n",
    "trainval_indices = list(range(len(ds_train))) + [len(ds_train) + i for i in range(len(ds_val))]\n",
    "subset = torch.utils.data.Subset(ds, trainval_indices)\n",
    "dl_trainval = DataLoader(subset, batch_size=best[\"batch_size\"], shuffle=True,\n",
    "                         num_workers=0, pin_memory=(device.type==\"cuda\"),\n",
    "                         collate_fn=collate)\n",
    "\n",
    "model_best = build_model(best)\n",
    "opt_best   = optim.AdamW(model_best.parameters(), lr=best[\"lr\"], weight_decay=best[\"weight_decay\"])\n",
    "\n",
    "# warmup once\n",
    "try:\n",
    "    x_tab_b, img_b, y_b = next(iter(dl_trainval))\n",
    "    img_b, y_b = img_b.to(device), y_b.to(device)\n",
    "    x_tab_b = {k: v.to(device) for k, v in x_tab_b.items()}\n",
    "    _ = model_best(x_tab_b, img_b, y=y_b)\n",
    "except StopIteration:\n",
    "    pass\n",
    "\n",
    "for ep in range(FINAL_EPOCHS):\n",
    "    train_loss, train_acc = run_epoch(model_best, dl_trainval, opt=opt_best)\n",
    "    print(f\"[Final Train] Epoch {ep+1:02d} | loss={train_loss:.4f} | acc={train_acc:.4f}\")\n",
    "\n",
    "test_loss, test_acc = run_epoch(model_best, dl_test_best, opt=None)\n",
    "print(\"\\n=== FINAL TEST RESULTS (iSyncTab + NS-PFS, HAM10000) ===\")\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test loss:     {test_loss:.4f}\")\n",
    "print(\"Classes:\", ds.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a05cf3-fe90-4117-bf45-0b1b019dd731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cb6e7d-363b-4621-bdf7-046e9b4ab513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
